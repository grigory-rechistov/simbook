\chapter{Современная виртуализация}\label{virt}

\dictum[Harlan McGhan]{When this sort of deliberate disconnection from reality happens with people, it generally goes by names like deceit, fraud, misrepresentation, or simply lying. When it happens with computers, it’s called virtualization\footnotemark.}
\footnotetext{Когда подобный вид умышленного искажения реальности происходит в среде людей, его обычно называют обманом, мошенничеством, введением в заблуждение или просто ложью. Если же это происходит внутри компьютера, это зовётся виртуализацией.}

% Every day I look the same
% And the sun is always shining
% I look out and there is 3D
% I keep looking down and miss my shadow
% 
% Every day my hair is fine
% But one dot keeps changing colors
% I know my heritage is noble
% But still I feel like I'm a clone
% 
% 8 bits are enough for me
% This is not where I should be
% My life is more than information
% I want a life beyond emulation
% 
% I look out and every thing's too fast for me
% And I feel there must be more
% Every day I dream of where I've come from
% Now I know I'm just an emulation
% 
% The next time I see the serial cable
% I jump on the train and leave this world
% Now I'm an original, I'm like my ancestors
% And my hair is finally all yellow
% 
% 8 bits are enough for me
% This is not where I should be
% My life is more than information
%———--
% mind.in.a.box - 8 bits

\section{Введение}

Для понимания того, каким образом современные вычислительные системы, их новые свойства, инструкции и режимы призваны поддерживать виртуализацию, в этой главе мы рассмотрим теоретические основания возможности её \emph{эффективной} реализации. 

Виртуализация представляла интерес ещё до изобретения микропроцессора, во времена преобладания больших систем — мейэнфреймов, ресурсы которых были очень дорогими, и их простой был экономически недопустим. Виртуализация позволяла повысить степень утилизации таких систем, при этом избавив пользователей и прикладных программистов от необходимости переписывать своё ПО, так как с их точки зрения виртуальная машина была идентична физической. Пионером в этой области являлась фирма IBM с мэйнфреймами System/360, System/370, созданными в 1960--1970-х гг.

\section{Классический критерий виртуализуемости}

Неудивительно, что критерии возможности создания эффективного монитора виртуальных машин были получены примерно в то же время. Они сформулированы в классической работе 1974~г. Жеральда Попека  и Роберта Голдберга «Formal requirements for virtualizable third generation architectures»~\cite{popek}. Рассмотрим её основные предпосылки и сформулируем её основной вывод.

\subsection{Модель системы}

В дальнейшем используется упрощённое представление «стандартной» вычислительной системы, состоящей из (одного) центрального процессора и линейной однородной оперативной памяти. Периферийные устройства, а также средства взаимодействия с ними опускаются. Процессор поддерживает два режима работы: режим супервизора, используемый операционной системой, и режим пользователя, в котором исполняются прикладные приложения. Память поддерживает режим сегментации, используемый для организации виртуальной памяти.

Выдвигаемые требования на монитор виртуальных машин (ВМ): 

\begin{description*}

\item[Изоляция] — каждая виртуальная машина должна иметь доступ только к тем ресурсам, которые были ей назначены. Она не должна иметь возможности повлиять на работы как монитора, так и других ВМ.

\item[Эквивалентность] — любая программа, исполняемая под управлением ВМ, должна демонстрировать поведение, полностью идентичное её исполнению на реальной системе, \emph{за исключением} эффектов, вызванных двумя обстоятельствами: различием в количестве доступных ресурсов (например, ВМ может иметь меньший объём памяти) и длительностями операций (из-за возможности разделения времени исполнения с другими ВМ).

Отметим, что для симуляторов в общем смысле эквивалентность не является требованием, т.к. в случаях, когда хозяйская и гостевая архитектуры не совпадают, поведение гостя и хозяина различаются.

\item[Эффективность] — в оригинальной работе условие сформулировано следующим образом: «статистически преобладающее подмножество инструкций виртуального процессора должно исполняться напрямую хозяйским процессором, без вмешательства монитора ВМ». Другими словами, значительная часть инструкций должна симулироваться в режиме прямого исполнения. Требование эффективности является самым неоднозначным из трёх перечисленных требований, и мы вернёмся к нему в секции~\ref{sec:revising-efficiency}.

В случае симуляторов, основанных на интерпретации инструкций, условие эффективности не выполняется, т.к. каждая инструкция гостя требует обработки симулятором.

\end{description*}

\subsection{Классы инструкций}

Состояние процессора содержит минимум три регистра: $M$, определяющий, находится ли он в режиме супервизора $s$ или пользователя $u$, $P$ — указатель текущей инструкции и $R$ — состояние, определяющее границы текущего сегмента памяти\footnote{В простейшем случае $R=(l,b)$, где $l$ — адрес начала диапазона, $b$ — его длина.}. При исполнении каждая инструкция $i$ в общем случае может изменить как $(M,P,R)$, так и память $E$, т.е. она является функцией преобразования 

$$(M_1,P_1,R_1,E_1) \overset{i}\mapsto (M_2,P_2,R_2,E_2).$$ 

Память $E$ состоит из фиксированного числа ячеек, к которым можно обращаться по их номеру $t$, например, $E[t]$. Размер памяти и ячеек для данного рассмотрения несущественен.

Считается, что для некоторых входных условий инструкция вызывает исключение \textit{ловушки} (\abbr trap), если в результате её исполнения содержимое памяти не изменяется, кроме единственной ячейки $E[0]$, в которую  помещается предыдущее состояние процессора $(M_1,P_1,R_1)$. Новое состояние процессора $(M_2,P_2,R_2)$ при этом копируется из $E[1]$. Другими словами, ловушка позволяет сохранить полное состояние программы на момент до начала исполнения её последней инструкции и передать управление обработчику, в случае обычных систем обычно работающему в режиме супервизора и призванного обеспечить дополнительные действия над состоянием системы, а затем вернуть управление в программу, восстановив состояние из $E[0]$.

Далее, ловушки могут иметь два признака.
\begin{enumerate*}
\item Вызванные попыткой изменить состояние процессора (ловушка \textit{потока управления}).

\item Обращения к содержимому памяти, выходящему за пределы диапазона, определённого в $R$ (ловушка \textit{защиты памяти}). 
\end{enumerate*}

Отметим, что эти признаки не взаимоисключающие. То есть результатом исполнения могут быть одновременно ловушка потока управления и защиты памяти.

Машинные инструкции рассматриваемого процессора можно классифицировать следующим образом:

\begin{description*}
\item[Привилегированные (\abbr privileged).] Инструкции, исполнение которых с $M = u$ всегда вызывает ловушку потока управления. Другими словами, такая инструкция может исполняться только в режиме супервизора, иначе она обязательно вызывает исключение.

\item[Служебные (\abbr sensitive\footnotemark).]\footnotetext{Установившего русского термина для этого понятия нет. Иногда в литературе встречается перевод «чувствительные» инструкции.} Класс состоит из двух подклассов. 1. Инструкции, исполнение которых закончилось без ловушки защиты памяти и вызвало изменение $M$ и/или $R$. Они могут менять режим процессора из супервизора в пользовательский или обратно или изменять положение и размер доступного сегмента памяти. 2. Инструкции, поведение которых в случаях, когда они не вызывают ловушку защиты памяти, зависят или от режима $M$, или от значения $R$.

\item[Безвредные (\abbr innocuous).] Не являющиеся служебными. Самый широкий класс инструкций, не манипулирующие ничем, кроме указателя инструкций $P$ и памяти $E$, поведение которых не зависит от того, в каком режиме или с каким адресом в памяти они расположены.

\end{description*}

\subsection[Достаточное условие]{Достаточное условие построения монитора ВМ} 

Соблюдение трёх сформулированных выше условий возможности построения монитора виртуальных машин даётся в следующем предложении: \textbf{множество служебных инструкций является подмножеством привилегированных инструкций} (рис.~\ref{fig:vm-sufficient-condition}). Опуская формальное доказательство теоремы 1 из статьи, отметим следующие обстоятельства.

\begin{itemize*}
    \item Изоляция обеспечивается размещением монитора в режиме супервизора, а ВМ — только в пользовательском. При этом последние не могут самовольно изменить системные ресурсы $(M,R)$ — попытка вызовет ловушку потока управления на служебной инструкции и переход в монитор, а также память $E[0,1]$ из-за того, что конфигурация $R$ не допускает этого, и процессор выполнит ловушку защиты памяти.
    \item Эквивалентность доказывается тем, что безвредные инструкции выполняются одинаково вне зависимости от того, присутствует ли в системе монитор или нет, а служебные всегда вызывают исключение и интерпретируются. Отметим, что даже в описанной выше простой схеме проявляется первое ослабляющее условие: даже без учёта памяти, необходимой для хранения кода и данных гипервизора, объём доступной для ВМ памяти будет как минимум на две ячейки меньше, чем имеется у хозяйской системы.
    \item Эффективность гарантируется тем, что все безвредные инструкции внутри ВМ исполняются напрямую, без замедления. При этом подразумевается, что их множество включает в себя «статистически преобладающее подмножество инструкций виртуального процессора».
\end{itemize*}

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/vm-sufficient-condition}
    \caption[Выполнение условия виртуализуемости]{Выполнение условия виртуализуемости. Множество служебных инструкций является подмножеством привилегированных}
    \label{fig:vm-sufficient-condition}
\end{figure}

\section{Ограничения применимости критерия виртуализуемости}\label{sec:revising-efficiency}

Несмотря на простоту использованной модели и полученных из неё выводов, работа Голдберга и Попека является актуальной до сих пор. Следует отметить, что несоблюдение описанных в ней условий вовсе не делает создание или использование виртуальных машин на некоторой архитектуре принципиально невозможным, и есть практические примеры реализаций, подтверждающие это. Однако соблюсти оптимальный баланс между тремя свойствами: изоляцией, эквивалентностью и эффективностью, — становится невозможным. Чаще всего расплачиваться приходится скоростью работы виртуальных машин из-за необходимости тщательного поиска и программного контроля за исполнением ими служебных, но не привилегированных инструкций, так как сама аппаратура не обеспечивает этого (рис.~\ref{fig:vm-bad-condition}). Даже единственная такая инструкция, исполненная напрямую ВМ, угрожает стабильной работе монитора, и поэтому он вынужден сканировать весь поток гостевых инструкций.

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/vm-bad-condition}
    \caption[Невыполнение условия виртуализуемости]{Невыполнение условия виртуализуемости. Служебные, но не привилегированные инструкции требуют реализации сложной логики в мониторе}
    \label{fig:vm-bad-condition}
\end{figure}

В самой работе~\cite{popek} присутствуют как явно указанные упрощения исследуемой структуры реальных систем (отсутствие периферии и системы ввода-вывода), так и неявные предположения о структуре исполняемых гостевых программ (почти полностью состоящих из безвредных инструкций) и хозяйских систем (однопроцессорность).

Рассмотрим теперь данные ограничения более детально, а также предложим, каким образом можно расширить степень применимости критерия к дополнительным ресурсам, требующим виртуализации, и таким образом повысить его практическую ценность для архитекторов новых вычислительных систем.

\subsection{Структура гостевых программ}

Для эффективной работы программ внутри ВМ необходимо, чтобы большая часть их инструкций являлись безвредными. Как правило, это верно для прикладных приложений. Операционные системы, в свою очередь, предназначены для управления ресурсами системы, что подразумевает использование ими привилегированных и служебных инструкций, и монитору приходится их перехватывать и интерпретировать с соответствующим падением производительности. Поэтому в идеале в наборе инструкций должно быть как можно меньше привилегированных для того, чтобы частота возникновения ловушек была минимальной.

\subsection{Периферия}

Поскольку периферийные устройства являются служебным ресурсом, очевидно, что для обеспечения условий изоляции и эквивалентности необходимо, чтобы все попытки доступа к ним были контролируемы монитором ВМ так же, как они контролируются в многозадачной операционной системе её ядром. В настоящее время доступ к устройствам чаще всего производится через механизм отражения их в физической памяти системы (\abbr memory mapped I/O), что означает, что внутри монитора это чтение/запись некоторых регионов должно или вызывать ловушку защиты памяти, или быть не служебным, т.е. не вызывать ловушку и не влиять на состояние неконтролируемым образом.

Интенсивность взаимодействия приложений с периферией может быть различна и определяется их функциональностью, что сказывается на их замедлении при виртуализации. Кроме того, монитор ВМ может делать различные классы периферии, присутствующей на хозяине, доступными внутри нескольких ВМ различными способами.

\begin{description*}
    \item[Выделенное устройство] — устройство, доступное исключительно внутри одной гостевой системы. Примеры: клавиатура, монитор.
    \item[Разделяемое] — общее для нескольких гостей. Такое устройство или имеет несколько частей, каждая из которых  выделена для нужд одного из них (\abbr partitioned mode), например, жёсткий диск с несколькими разделами, или подключается к каждому из них поочерёдно (\abbr shared mode). Пример: сетевая карта.
    \item[Полностью виртуальное] — устройство, отсутствующее в реальной системе (или присутствующее, но в ограниченном количестве) и моделируемое программно внутри монитора. Примеры: таймеры прерываний — каждый гость имеет собственный таймер, несмотря на то, что в хозяйской системе есть только один, и он используется для собственных нужд монитора.
\end{description*}


\subsection{Прерывания}

Прерывания являются механизмом оповещения процессора о событиях внешних устройств, требующих внимания операционной системы. В случае использования виртуальных машин монитор должен иметь возможность контролировать доставку прерываний, так как часть или все из них необходимо обрабатывать именно внутри монитора. Например, прерывание таймера может быть использовано им для отслеживания/ограничения использования гостями процессорного времени и для возможности переключения между несколькими одновременно запущенными ВМ. Кроме того, в случае нескольких гостей заранее неясно, какому из них следует доставить прерывание, и принять решение должен монитор.

Простейшее решение, обеспечивающее изоляцию, — это направлять \textbf{все} прерывания в монитор ВМ. Эквивалентность при этом будет обеспечиваться им самим: прерывание при необходимости будет доставлено внутрь гостя через симуляцию изменения его состояния. Монитор может дополнительно создавать виртуальные прерывания, обусловленные только логикой его работы, а не внешними событиями. Однако эффективность такого решения не будет оптимальной. Как правило, реакция системы на прерывание должна произойти в течение ограниченного времени, иначе она потеряет смысл для внешнего устройства или будет иметь катастрофические последствия для системы в целом. Введение слоя виртуализации увеличивает задержку между моментом  возникновения события и моментом его обработки в госте по сравнению с системой без виртуализации. Более эффективным является аппаратный контроль за доставкой прерываний, позволяющий часть из них сделать безвредными для состояния системы и не требовать каждый раз вмешательства программы монитора.

\subsection{Многопроцессорные системы}

\subsubsection{Синхронизация и виртуализация}

Введение в рассмотрение нескольких хозяйских и гостевых процессоров оставляет условие эффективной виртуализуемости в силе. Однако необходимо обратить внимание на выполнение условий эффективности работы многопоточных приложений внутри ВМ. В отличие от однопоточных, для них характерны процессы синхронизации частей программы, исполняющихся на различных виртуальных процессорах. При этом все участвующие потоки ожидают, когда все они достигнут заранее определённой точки алгоритма, т.н. барьера. В случае виртуализации системы один или несколько гостевых потоков могуть оказаться неактивными, вытесненными монитором, из-за чего остальные будут попусту тратить время.

Примером такого неэффективного поведения гостевых систем является синхронизация с задействованием циклических блокировок (\abbr spin lock) внутри ВМ~\cite{southern-v12n}. Будучи неэффективной и поэтому неиспользуемой для однопроцессорных систем, в случае нескольких процессоров она является легковесной альтернативой классическим замкам (\abbr lock), используемым для входа в критические секции параллельных алгоритмов. Чаще всего они используются внутри операционной системы, но не пользовательских программ, так как только ОС может точно определить, какие из системных ресурсов могут быть эффективно защищены с помощью циклических блокировок. Однако в случае виртуальной машины планированием ресурсов занимается не ОС, а монитор ВМ, который в общем случае не осведомлён о них и может вытеснить поток, способный освободить ресурс, тогда как второй поток будет выполнять циклическую блокировку, бесполезно тратя процессорное время. Оптимальным решением при этом является деактивация заблокированного потока до тех пор, пока нужный ему ресурс не освободится.

Существующие решения для данной проблемы описанны ниже.

\begin{enumerate*}
    \item Монитор ВМ может пытаться детектировать использование циклических блокировок гостевой ОС. Это требует анализа кода перед исполнением, установки точек останова по адресам замка. Способ не отличается универсальностью и надёжностью детектирования.
    \item Гостевая система может сигнализировать монитору о намерении использовать циклическую блокировку с помощью специальной инструкции. Способ более надёжный, однако требующий модификации кода гостевой ОС.
\end{enumerate*}

\subsubsection{Прерывания в многопроцессорных системах}

Наконец, отметим, что схемы доставки и обработки прерываний в системах с несколькими процессорами также более сложны, и это приходится учитывать при создании монитора ВМ для таких систем, при этом его эффективность может оказаться ниже, чем у однопроцессорного эквивалента. 

\subsection{Преобразование адресов}

Модель машинных инструкций, использованная ранее для формулировки основного утверждения данной главы, использовала простую линейную схему трансляции адресов, основанную на сегментации, популярную в 70-х годах прошлого века. Она является вычислительно простой, не изменяется при введении монитора ВМ, и поэтому анализа влияния механизма преобразования адресов на эффективность не производилось.

В настоящее время механизмы страничной виртуальной памяти и применяют нелинейное преобразование виртуальных адресов пользовательских приложений в физические адреса, используемые аппаратурой. Участвующий при этом системный ресурс — регистр-указатель адреса таблицы преобразований\footnote{Чаще всего на практике используется несколько таблиц, образующих иерархию, имеющую общий корень.}. В случае использования ВМ этот указатель необходимо виртуализовать, так как у каждой гостевой системы содержимое регистра своё, как и положение/содержимое таблицы. Стоимость программной реализации этого механизма внутри монитора высока, поэтому приложения, активно использующие память, могут терять в эффективности при виртуализации.

Для решения этой проблемы используется двухуровневая аппаратная трансляция адресов (рис.~\ref{fig:two-level-translation}). Гостевые ОС видят только первый уровень, тогда как генерируемый для них физический адрес в дальнейшем транслируется вторым уровнем в настоящий адрес.

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/two-level-translation}
    \caption[Двухуровневая трансляция адресов]{Двухуровневая трансляция адресов. Первый уровень контролируется гостевыми ОС, второй — монитором виртуальных машин}
    \label{fig:two-level-translation}
\end{figure}

\paragraph{TLB.} Ещё один блок, отвечающий за преобразование адресов, — это буфер ассоциативной трансляции (\abbr translation lookaside buffer, TLB), состоящий из нескольких записей. Каждая гостевая система имеет своё содержимое TLB, поэтому при смене активной ВМ или переходе в монитор он должен быть сброшен. Это негативно сказывается на производительности систем, так как восстановление его содержимого требует времени, в течение которого приходится использовать менее эффективное обращение к таблице трансляций, расположенной в памяти.

Решение состоит в разделении ресурсов TLB между всеми системами~\cite{YANG:2008}. Каждая строка буфера ассоциируется с идентификатором — тэгом, уникальным для каждой ВМ. При поиске в нём аппаратурой учитываются только строки, тэг которых соответствует текущей ВМ.

\paragraph{Преобразование адресов для периферийных устройств.} Кроме процессоров к оперативной памяти напрямую могут обращаться и периферийные устройства —  с помощью технологии DMA (\abbr direct memory access). При этом обращения в классических системах без виртуализации идёт по физическим адресам. Очевидно, что внутри виртуальной машины необходимо транслировать такие адреса, что превращается в накладные расходы и понижение эффективности монитора. 

Решение состоит в использовании устройства IOMMU (\abbr Input output memory management unit), позволяющего контролировать обращения хозяйских устройств к физической памяти. 

\subsection{Расширение принципа}

Расширим условие виртуализуемости, заменив в нём слово «инструкция» на «операция»: \textbf{множество служебных \emph{операций} является подмножеством привилегированных}. При этом под операцией будем подразумевать любую архитектурно определённую активность по чтению или изменению состояния системы, в том числе инструкции, прерывания, доступы к устройствам, преобразования адресов и т.п.

При этом условие повышения эффективности виртуализации будет звучать следующим образом: \textbf{в архитектуре системы должно присутствовать минимальное число служебных операций}. Достигать его можно двумя способами: переводя служебные инструкции в разряд безвредных или уменьшая число привилегированных. Для этого большинство архитектур пошло по пути добавления в регистр состояния $M$ нового режима $r$ — режима монитора ВМ (\abbr root mode). Он соотносится с режимом $s$ так, как $s$ — с $u$; другими словами, \emph{обновлёный} класс привилегированных инструкций теперь вызывает ловушку потока управления, переводящую процессор из $s$ в $r$.

\section{Статус поддержки в современных архитектурах}

Рассмотрим основные современные архитектуры вычислительных систем, используемых на серверах, рабочих станциях, а также во встраиваемых системах, с точки зрения практической реализации описанных выше теоретических принципов. См. также серию статей~\cite{mpr-03-05-07-01,mpr-03-12-07-01,mpr-03-26-07-01}.

\subsection{IBM POWER}

Компания IBM была одной из первых, выведших архитектуру с аппаратной поддержкой виртуализации на рынок серверных микропроцессоров в серии POWER4 в 2001 году. Она предназначалась для создания изолированных логических разделов (\abbr logical partitions, LPAR), с каждым из которых ассоциированы один или несколько процессоров и ресурсы ввода-вывода. Для этого в процессор был добавлен новый режим гипервизора к уже присутсвовавшим режимам супервизора и пользователя. Для защиты памяти каждый LPAR ограничен в режиме с отключенной трансляцией адресов и имеет доступ лишь к небольшому приватному региону памяти; для использования остальной памяти гостевая ОС обязана включить трансляцию, контролируемую монитором ВМ.

В 2004 году развитие этой архитектуры, названное POWER5, принесло серьёзные усовершенствования механизмов виртуализации. Так, было добавлено новое устройство таймера, доступное только для монитора ВМ, что позволило ему контролировать гостевые системы более точно и выделять им процессорные ресурсы с точностью до сотой доли от процессора. Также монитор ВМ получил возможность контролировать адрес доставки прерываний — в LPAR или в гипервизор. Самым важным же нововведением являлся тот факт, что присутствие гипервизора являлось обязательным — он загружался и управлял системными ресурсами, даже если в системе присутствовал единственный LPAR-раздел. Поддерживаемые ОС (AIX, Linux, IBM~i) были модифицированы с учётом этого, чтобы поддерживать своеобразную паравиртуализационную схему. Для управления устройствами ввода-вывода один (или два, для балансировки нагрузки) из LPAR загружает специальную операционную систему — virtual I/O server (VIOS), предоставляющую эти ресурсы для остальных разделов.

\subsection{SPARC}

Компания Sun, развивавшая системы UltraSPARC и ОС Solaris, предлагала виртуализацию уровня ОС (т.н. контейнеры или зоны) начиная с 2004~г. В 2005 году в многопоточных процессорах Niagara~1 была представлена аппаратная виртуализация. При этом гранулярность виртуализации была равна одному потоку (всего чип имел восемь ядер, четыре потока на каждом). 

Для взаимодействия ОС и гипервизора был представлен публичный и стабильный интерфейс для привилегированных приложений~\cite{sun4v-spec}, скрывающий от ОС большинство архитектурных регистров.

Для трансляции адресов используется описанная ранее двухуровневая схема с виртуальными, реальными и физическими адресами. При этом TLB не хранит промежуточный адрес трансляции. 

\subsection{Intel IA-32 и AMD AMD64}

В отличие от POWER и SPARC, архитектура IA-32 (в т.ч. её 64-битные расширения Intel 64 и AMD64) никогда не была подконтрольна одной компании, которая могла бы добавлять функциональность (пара)виртуализации между аппаратурой и ОС, нарушающую обратную совместимость с существующими операционными системами. Кроме того, в ней явно нарушены условия эффективной виртуализации — около 17 служебных инструкций не являются привилегированными, что мешало создать аппаратно поддерживаемые мониторы ВМ. Однако программные мониторы существовали и до 2006 года, когда Intel представила технологию VT-x, а AMD — похожую, но несовместимую с ней AMD-V. 

Были представлены новые режимы процессора — VMX root и non root, и уже существовавшие режимы привилегий 0--3 могут быть использованы в обоих из них. Переход между режимами может быть осуществлён с помощью новых инструкций \texttt{vmxon} и \texttt{vmxoff}. 

Для хранения состояния гостевых систем и монитора используется новая структура VMCS (\abbr virtual machine control structure), копии которой размещены в физической памяти и доступны для монитора ВМ.

Интересным решением является конфигурируемость того, какие события в госте будут вызывать событие ловушки и переход в гипервизор, а какие оставлены на обработку ОС. Например, для каждого гостя можно выбрать, будут ли внешние прерывания обрабатываться им или монитором; запись в какие биты контрольных регистров \texttt{CR0} и \texttt{CR4} будет перехватываться; какие исключения должны обрабатываться гостем, а какие — монитором и т.п. Данное решение позволяет добиваться компромисса между степенью контроля над каждой ВМ и эффективностью виртуализации. Таким образом, для доверенных гостей контроль монитора может быть ослаблен, тогда как одновременно исполняющиеся с ними сторонние ОС будут всё так же под его строгим наблюдением. Для оптимизации работы TLB используется описанная выше техника тэгирования его записей с помощью ASID (\abbr address space identifier). Для ускорения процесса трансляции адресов двухуровневая схема трансляции получила имя Intel EPT (\abbr extended page table).

\subsection{Intel IA-64 (Itanium)}

Intel добавила аппаратную виртуализацию в Itanium (технология VT-i~\cite{vtx}) одновременно с IA-32 — в 2006 году. Специальный режим включался с помощью нового бита в статусном регистре \texttt{PRS.vm}. С включенным битом ранее служебные, но не привилегированные инструкции начинают вызывать ловушку и выход в монитор. Для возвращения в режим гостевой ОС используется инструкция \texttt{vmsw}. Часть инструкций, являющаяся служебными, при включенном режиме виртуализации генерируют новый вид синхронного исключения, для которого выделен собственный обработчик.

Поскольку операционная система обращается к аппаратуре посредством специального интерфейса PAL (\abbr processor abstraction level), последний был расширен, чтобы поддерживать такие операции, как создание и уничтожение окружений для гостевых систем, сохранение и загрузка их состояния, конфигурирование виртуальных ресурсов и т.д. Можно отметить, что добавление аппаратной виртуализации в IA-64 потребовало меньшего количества усилий по сравнению с IA-32.

\subsection{ARM}

Архитектура ARM изначально была предназначена для встраиваемых и мобильных систем, эффективная виртуализация которых, по сравнению с серверными системами, долгое время не являлась ключевым фактором коммерческого и технологического успеха. Однако в последние годы наметилась тенденция к использованию ВМ на мобильных устройствах для обеспечения защиты критически важных частей системного кода, например, криптографических ключей, используемых при обработке коммерческих транзакций. Кроме того, процессоры ARM стали продвигаться на рынок серверных систем, и это потребовало расширить архитектуру и добавить в неё такие возможности, как поддержка адресации больших объёмов памяти и виртуализация.

Оба аспекта были отражены в избранном компанией ARM подходе к развитию своей архитектуры. На рис.~\ref{fig:arm-vt-trustzone} представлена схема, подразумевающая вложенность двух уровней виртуализации, представленная в 2010 году в обновлении архитектуры Cortex A15~\cite{arm-a15}. 

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/arm-vt-trustzone}
    \caption[Виртуализация ARM]{Виртуализация ARM. Монитор TrustZone обеспечивает изоляцию и криптографическую аутентификацию доверенного «мира». В обычном «мире» используется собственный монитор ВМ}
    \label{fig:arm-vt-trustzone}
\end{figure}

Для обеспечения изоляции критических компонент используется первый слой виртуализации, называемый TrustZone. С его помощью все запущенные программные компоненты  делятся на два «мира» — доверенный и обычный. В первой среде исполняются те части системы, работа которых не должна быть подвластна внешним влияниям обычного кода. Во второй среде исполняются пользовательские приложения и операционная система, которые теоретически могут быть скомпрометированы. Однако обычный «мир» не имеет доступа к доверенному. Монитор TrustZone обеспечивает доступ в обратном направлении, что позволяет доверенному коду контролировать состояние аппаратуры.

Второй слой виртуализации исполняется под управлением недоверенного монитора и предоставляет возможности мультиплексирования работы нескольких пользовательских ОС. В нём добавлены новые инструкции \texttt{HVC} и \texttt{ERET} для входа и выхода в/из режим(а) гипервизора. Для событий ловушки использован ранее зарезервированный вектор прерываний 0x14, добавлены новые регистры: указатель стэка \texttt{SPSR}, состояние виртуальных ресурсов \texttt{HCR} и регистр «синдрома» \texttt{HSR}, в котором хранится причина выхода из гостя  в монитор, что позволяет последнему быстро проанализировать ситуацию и проэмулировать необходимую функциональность без избыточного чтения состояния гостя.

Так же, как это сделано в рассмотренных ранее архитектурах, для ускорения механизмов трансляции адресов используется двухуровневая схема, в которой физические адреса гостевых ОС являются промежуточными. Внешние прерывания могут быть настроены как на доставку монитору, который потом перенаправляет их в гостя с помощью механизма виртуальных прерываний, так и на прямую отправку в гостевую систему.

\subsection{MIPS}

Процессоры MIPS развивались в направлении, обратном наблюдаемому для ARM: от высокопроизводительных систем к встраиваемым и мобильным. Тем не менее, аппаратная виртуализация для неё появилась относительно недавно, в 2012 г. Архитектура MIPS R5 принесла режим виртуализации MIPS VZ~\cite{mips-vz}. Он доступен как для 32-битного, так и для 64-битного варианта архитектуры.

Добавленное архитектурное состояние позволяет хранить контекст ВМ и монитора отдельно. Например, для нужд гипервизора введена копия системного регистра \texttt{COP0}, независимая от копии гостя. Это позволяет оптимизировать время переключения между ними, в то время как переключение между несколькими гостевыми ОС требует обновления \texttt{COP0} содержимым из памяти и является менее эффективным. Кроме того, часть бит гостевого регистра, описывающие набор возможностей текущего варианта архитектуры и потому ранее используемые только для чтения, из режима монитора доступны для записи, что позволяет ему декларировать возможности, отличные от действительно присутствующих на хозяине.

Привилегии гипервизора, операционной системы и пользователя образуют т.н. луковую (\abbr onion) модель. В ней обработка прерываний идёт снаружи внутрь, т.е. сначала каждое из них проверяется на соответствие правилам монитора, затем ОС. Синхронные исключения (ловушки), наоборот, обрабатываются сперва ОС, а затем монитором.

Так же, как это сделано в рассмотренных ранее архитектурах, для ускорения механизмов трансляции адресов используют тэги в TLB и двухуровневую трансляцию в MMU. Для поддержки разработки паравиртуализационных гостей добавлена новая инструкция \texttt{hypercall}, вызывающая ловушку и выход в режим монитора.

\section{Вложенная и рекурсивная виртуализация}

%But it's tortoises all the way down!
\dictum[Космологическая гипотеза]{Каждая черепаха стоит на спине следующей!}

Сценарий, в котором один или несколько мониторов виртуальных машин запускается под управлением других гипервизоров, называется \textit{рекурсивной виртуализацией}. Теоретически она может быть не ограничена только двумя уровнями — внутри каждого монитора ВМ может исполняться следующий, тем самым образуя иерархию гипервизоров.

Кроме чисто академического любопытства, у возможности запуска одного гипервизора под управлением другого есть и практические применения.

\begin{itemize*}
    \item Отладка и тестирование ВМ. Любой монитор — достаточно сложная программа, к которой обычные методы отладки приложений и даже ОС неприменимы, т.к. он загружается очень рано в процессе работы системы, когда отладчик подключить затруднительно. Исполнение под управлением симулятора позволяет инспектировать и контролировать его работу с самой первой инструкции.
    \item Миграция. Запуск монитора ВМ системы и всех приложений внутри него под управлением нового монитора на новой системе позволяет значительно облегчить миграцию таких систем между поколениями серверов — отпадает необходимость заново устанавливать и конфигурировать их на новой системе с нуля.
    \item Поддержка гостевых сценариев с уже встроенным монитором ВМ, например, запуск Microsoft Windows 7 с включенным MS Windows XP Mode, или же задачи разработки под Windows Phone 8, который требует включения в хозяйской ОС режима Hyper-V.
\end{itemize*}

Голдберг и Попек в своей упомянутой ранее работе рассмотрели вопросы эффективной поддержки в том числе и рекурсивной виртуализации. Однако их выводы, к сожалению, не учитывают многие из упомянутых выше особенностей современных систем.

\subsection{Вложенная виртуализация}

Рассмотрим следующий важный частный случай, который получил название вложенная виртуализация (\abbr nested virtualization). В нём участвуют следующие сущности (рис.~\ref{fig:nested-virt}).

\begin{itemize}
\item L0 — монитор первого уровня, запущенный непосредственно на аппаратуре.
\item L1 — вложенный монитор, исполняющийся в качестве гостя внутри L0.
\item L2 — гостевая система, исполняемая под управлением L1.
\end{itemize}

Если рассмотреть свойства виртуального процессора, видимого внутри гостевой системы L1, то они будут отличаться от тех, что имел настоящий, физический L0: аппаратной поддержки виртуализации в нём не будет! Поэтому L1 будет вынужден программно моделировать всю ту функциональность, которую L0 имеет напрямую из аппаратуры, значительно теряя при этом в производительности.

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/nested-virt}
    \caption[Сценарий вложенной виртуализации]{Определения сущностей, взаимодействующих в сценариях вложенной виртуализации}
    \label{fig:nested-virt}
\end{figure}

Фактически L0 и L1 — это «бюрократический» код, исполнение которого нежелательно, но неизбежно. L2 — это полезная нагрузка, приложения польователя. Чем больше времени проводится внутри L2 и чем меньше в L1 и L0, а также в состояниях переходов между ними, тем более эффективно работает вычислительная система.

Какими способами можно повысить эффективность?

\begin{itemize}
\item Уменьшить задержки при переходах между режимами супервизора $r$ и $s$/$u$. См. также таблицу~\ref{tab:vmexit-latency} в секции~\ref{sec:software-prescan}.
\item Уменьшить число выходов из L2, разрешив большему числу операций исполняться без генерации ловушек. Естественно, это также ускорит сценарии простой одноуровневой виртуализации.
\item Уменьшить число выходов из L1 в L0. Как мы увидим далее, часть операций вложенного монитора может быть исполнена напрямую, без выхода в L0.
\item Научить L0, L1 «договариваться» друг с другом. Это приводит к идее паравиртуализации, которая сопряжена с модификацией гостевых окружений.
\end{itemize}

Итак, аппаратура не поддерживает напрямую L2, а все возможности по ускорению были использованы для обеспечения работы L1. Один из подходов состоит в создании плоской структуры из гостей L1 и L2~\cite{turtles} (рис.~\ref{fig:nested-virt-flat}).

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/nested-virt-flat}
    \caption[Переход L2 под управление L0]{Переход L2 под управление L0}
    \label{fig:nested-virt-flat}
\end{figure}

В этом случае на L0 возлагается задача управления гостями как L1, так и L2. Для последних приходится модифицировать контрольные структуры, управляющие переходами между режимами $r$ и $s$, чтобы выход происходил именно в L0. Это не совсем соответствует представлениям L1 о том, что происходит в системе. С другой стороны, как будет показано уже в следующем параграфе статьи, L1 всё равно не имеет прямого контроля над переходами между режимами, и поэтому при правильной реализации плоской структуры никто из гостей не сможет заметить подмены.

\subsection{Теневые структуры}

Прилагательное «теневой» (\abbr shadow) для элементов архитектурного состояния постоянно используется во всевозможной литературе и документации по виртуализации.

Регистры общего назначения, модифицируемые гостевым окружением, не могут повлиять на корректность работы монитора. Поэтому все инструкции, которые работают только с ними, могут исполняться гостем напрямую (т.е. они безвредные). Какое бы значение не сохранилось в них после выхода из гостя, монитор при необходимости всегда может загрузить в регистр новое значение пост-фактум. С другой стороны, системные регистры, определяют в том числе то, как будут отображаться виртуальные адреса для всех доступов в память. Если бы гость мог записывать в него произвольные значения, то монитор не смог бы работать нормально. По этой причине создаётся \textit{тень} — копия критичного для работы регистра, хранимая в памяти. Все попытки доступа гостя к оригинальному ресурсу перехватываются монитором и эмулируются, используя значения из теневой копии.

Необходимость программного моделирования работы с теневыми структурами является одним из источников потери производительности работы гостя. Поэтому некоторые элементы архитектурного состояния получают аппаратную поддержку тени: в режиме $s$ обращения к такому регистру сразу перенаправляются в его теневую копию.
Так, в архитектуре Intel® VT-x \cite{vtx} как минимум следующие структуры процессора получают тень: CR0, CR4, CR8, GSBASE.

\subsection{Shadow VMCS}
Итак, реализация теневой структуры для некоторого архитектурного состояния в L0 может быть чисто программная. Однако ценой этому будет необходимость постоянного перехвата обращений к нему. Так, в \cite{nested-virt-kvm-2013} упоминается, что один выход из L2 в L1 на IA-32 вызывает около 40-50 настоящих переходов из L1 в L0. Значительная часть этих переходов вызвана всего двумя инструкциями — VMREAD и VMWRITE (рис. \ref{fig:nested-vmread}).

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/nested-vmread}
    \caption[Сравнение числа переходов между уровнями виртуализации]{Сравнение числа переходов между уровнями виртуализации для одного и двух уровней вложенности мониторов}
    \label{fig:nested-vmread}
\end{figure}

Эти инструкции работают над структурой VMCS (\abbr virtual machine control structure), контролирующей переходы между режимами виртуализации. Поскольку напрямую монитору L1 нельзя разрешать её изменять, монитор L0 создаёт теневую копию, а затем эмулирует работу с ней, перехватывая эти две инструкции. В результате время обработки каждого выхода из L2 возрастает значительно.

Поэтому в последующих версиях Intel® VT-x VMCS обзавелась теневой копией — shadow VMCS. Эта структура хранится в памяти, имеет аналогичное обычной VMCS содержание и может быть прочитана/изменена с помощью инструкций VMREAD/VMWRITE, в том числе из режима $s$ без генерации ловушки (рис. \ref{fig:nested-vmread-shadow}).
В результате значительная часть переходов L1 → L0 устраняется. %Однако, shadow VMCS не может быть использована для входа/выхода в  и root режимы — для этого всё так же используется оригинальная VMCS, управляемая L0.


\begin{figure}[htb]
    \centering
    \inputpicture{drawings/nested-vmread-shadow}
    \caption[Использование shadow VMCS]{Использование shadow VMCS для нужд вложенной виртуализации позволяет уменьшить число переходов в L0}
    \label{fig:nested-vmread-shadow}
\end{figure}


\subsection{Shadow EPT}

Отмечу, что Intel® EPT (\abbr Extended Page Table), упомянутая в — это также техника аппаратного ускорения работы с другой теневой структурой, используемой для трансляции адресов. Вместо того, чтобы следить за всем деревом таблиц трансляций гостя и перехватывать попытки его чтения и модификации, для него создаётся своя собственная аппаратная структура. Настоящие физические адреса получаются после трансляции гостевых физических адресов, что также делается аппаратурой.

В случае вложенной виртуализации, как и в случае с VMCS, мы приходим к той же самой проблеме: теперь уровней трансляции стало три (L2 → L1, L1 → L0 и L0 → физический адрес), но аппаратура поддерживает только два. Это означает, что один из уровней трансляции придётся моделировать программно.

Если моделировать L2 → L1, то, как и следовало ожидать, это приведёт к существенному замедлению работы. Эффект будет даже более значительный, чем в случае одного уровня: каждое исключение \#PF (\abbr page fault) и запись CR3 внутри L2 будет приводить к выходу в L0, а не в L1. Однако, если заметить \cite{nested-ept-kvm-2013}, что гостевые окружения L1 создаются гораздо реже, чем процессы в L2, то можно сделать программной (т.е. медленной) именно трансляцию L1 → L0, а для L2 → L1 задействовать освободившийся аппаратный (быстрый) EPT. Это напоминает мне идею из области компиляторных оптимизаций: следует оптимизировать самый вложенный цикл кода. В случае виртуализации — это самый вложенный гость.

\subsection{Рекурсивная виртуализация}

Вполне мыслимы (а значит, и практически реализуемы) сценарии рекурсивной виртуализации с третьим, четвёртым и более глубокими уровнями вложенности. Описанные выше приёмы поддержки двух уровней вложенности становятся очень непривлекательными. Они приносят существенные алгоритмические сложности, призванные обойти ограничения аппаратуры, которые состоят в том, что режим гостя не поддерживает повторного входа в самого себя.

История вычислительной техники напоминает о похожих проблемах и подсказывает решение. Ранний Fortran не поддерживал рекурсивный вызов процедур, потому что состояние локальных переменных (activation record) хранилось в статически выделяемой памяти. Повторный вызов уже исполняющейся процедуры затёр бы эту область, отрезав исполнению выход из процедуры. Решение, реализованное в современных языках программирования, состояло в поддержке стека из записей, хранящих данные вызванных процедур, а также адреса возврата.

Похожую ситуацию мы видим для, например, структуры VMCS — для неё используется абсолютный адрес, и данные в ней принадлежат монитору L0. Гость не может использовать эту же VMCS, иначе он рисковал бы затереть состояние хозяина. Если бы в аппаратуре поддерживался двусвязнный список VMCS, каждая последующая запись в котором принадлежала бы текущему монитору (а также была доступна всем вышестоящим над ним), то не приходилось бы прибегать к описанным выше ухищрениям по передаче L2 под командование L0. Выход из гостя передавал бы управление его монитору с одновременным переключением на предыдущую VMCS, а вход в режим гостя активировал бы следующую по списку.

Вторая особенность, ограничивающая производительность вложенной виртуализации — это нерациональная обработка синхронных исключений \cite{recursive-virt-poon}. При возникновении исключительной ситуации внутри вложенного гостя L$N$ управление всегда передаётся в L0, даже если единственная его задача после этого — это «спустить» обработку ситуации в ближайший к L$N$ монитор L($N-1$). Спуск сопровождается лавиной переключений состояний всех промежуточных мониторов.

Для эффективной рекурсивной виртуализации в архитектуре необходим механизм, позволяющий менять направление обработки некоторых исключительных событий: вместо фиксированного порядка L0 → L($N-1$) синхронные прерывания могут быть направлены L($N-1$) → L0. Вмешательство внешних мониторов требуется только если более вложенные не могут обработать ситуацию.

Как для прерываний, так и для ловушек это часто оказывается неоптимальным — событие должно пройти несколько уровней иерархии, каждый из которых внесёт задержку на его обработку. На рис.~\ref{fig:recursive-vm} показана обработка двух типов сообщений — прерывания, возникшего во внешней аппаратуре, и ловушки потока управления, случившейся внутри приложения.

\begin{figure}[htb]
    \centering
    \inputpicture{drawings/recursive-vm}
    \caption[Рекурсивная виртуализация]{Рекурсивная виртуализация. Все события должны обрабатываться внешним монитором, который спускает их вниз по иерархии, при этом формируется задержка}
    \label{fig:recursive-vm}
\end{figure}

Для оптимальной обработки различных типов ловушек и прерываний для каждого из них должен быть выбран уровень иерархии мониторов ВМ, и при возникновении события управление должно передаваться напрямую этому уровню, минуя дополнительную обработку вышележащими уровнями и без связанных с этим накладных расходов.

\subsection{Поддержка в существующих решениях}
%SIE Sr: 
%\dictum[Andy Glew]{IBM did virtual machines better in 1985 than we do now}

Задаче аппаратной поддержки второго и более уровней вложенности виртуализации производители процессоров уделяют значительно меньше внимания, чем первому её уровню. Тем не менее такие работы существуют. Так, ещё в восьмидесятых годах двадцатого века для систем IBM/370~\cite{Osisek:1991:EIA:106229.120150} была реализована возможность запуска копий системного ПО внутри уже работающей на аппаратуре операционной системы. Для этой задачи была введена инструкция \texttt{SIE} (\abbr start interpreted execution)~\cite{sie-comp-arch}.

\section[Уменьшение частоты и выходов в монитор]{Уменьшение частоты и выходов в режим монитора с помощью предпросмотра инструкций}\label{sec:software-prescan}

В заключение данной главы рассмотрим eщё одну технику повышения эффективности виртуализации, связанную с уменьшением числа переключений между режимами.

Частые прерывания работы виртуальной машины из-за необходимости выхода в монитор негативно влияют на скорость симуляции.  Несмотря на то, что производители процессоров работают над уменьшением связанных с этими переходами задержек (для примера см. таблицу~\ref{tab:vmexit-latency}), они всё же достаточно существенны, чтобы пытаться минимизировать их частоту возникновения.

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|r|}\hline
\textbf{Микроархитектура} & \textbf{Дата запуска} & \textbf{Задержка, тактов} \\\hline
Prescott     & 3 кв. 2005 & 3963 \\\hline
Merom        & 2 кв. 2006 & 1579 \\\hline
Penryn       & 1 кв. 2008 & 1266 \\\hline
Nehalem      & 3 кв. 2009 & 1009 \\\hline
Westmere     & 1 кв. 2010 & 761 \\\hline
Sandy Bridge & 1 кв. 2011 & 784 \\\hline
Ivy Bridge   & 1 кв. 2012 & 822 \\\hline
Haswell      & 2 кв. 2013 & 652 \\\hline

\end{tabular}
\caption[Длительность перехода между режимами аппаратной виртуализации]{Длительность перехода между режимами аппаратной виртуализации для различных поколений микроархитектур процессоров Intel IA-32. Данные взяты из работы \cite{Agesen:2012:STA:2342821.2342856}, а также из экспериментов авторов}
\label{tab:vmexit-latency}
\end{table}

Как уже было обозначено в главе~\ref{bt}, если одна из техник симуляции оказывается неэффективной, имеет смысл переключиться на некоторую другую, например, на интерпретацию или двоичную трансляцию.

На практике исполнения ОС характерна ситуация, что инструкции, вызывающие ловушки потока управления, образуют \emph{кластера}, в которых две или более из них находятся недалеко друг от друга, тогда как расстояние между кластерами значительно. В следующем блоке кода для IA-32 приведён пример такого кластера. Звёздочкой обозначены все инструкции, вызывающие выход в монитор.

\begin{lstlisting}
* in %al,%dx
* out $0x80,%al
  mov %al,%cl
  mov %dl,$0xc0
* out %al,%dx
* out $0x80,%al
* out %al,%dx
* out $0x80,%al
\end{lstlisting}

Для того, чтобы избежать повторения сценария: выход из ВМ в монитор, интерпретация инструкции, обратный вход в ВМ только для того, чтобы на следующей инструкции вновь выйти в монитор, — используется \textit{предпросмотр} инструкций~\cite{Agesen:2012:STA:2342821.2342856}. После обработки ловушки, прежде чем монитор передаст управление обратно в ВМ, поток инструкций просматривается на несколько инструкций вперёд в поисках привилегированных инструкций. Если они обнаружены, симуляция на некоторое время переключается в режим двоичной трансляции. Тем самым избегается негативное влияние эффекта кластеризации привилегированных инструкций.


\input{virt-questions}

\iftoggle{webpaper}{
    \printbibliography[title={Литература}]
}{}

